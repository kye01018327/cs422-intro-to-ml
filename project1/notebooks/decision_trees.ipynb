{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b8083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log2\n",
    "from scripts.utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c993f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(Y):\n",
    "    classes, counts = np.unique(Y, return_counts=True)\n",
    "    p_C = counts / counts.sum()\n",
    "    calculate_entropy = np.sum([-p_c * log2(p_c) for p_c in p_C])\n",
    "    return calculate_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da4bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_gain(feature, labels):\n",
    "    # Calculate entropy of labels\n",
    "    H_labels = calculate_entropy(labels)\n",
    "    # Create set of classes and counts for feature\n",
    "    classes, counts = np.unique(feature, return_counts=True)\n",
    "\n",
    "    # Calculate entropy of feature\n",
    "    H_feature = 0\n",
    "    # Iterate through each c in set C\n",
    "    for cls, count in zip(classes, counts):\n",
    "        # Calculate p(t)\n",
    "        p_t = count / len(labels)\n",
    "        # Calculate H(t) or entropy of c\n",
    "        cls_labels = labels[feature == cls]\n",
    "        H_t = calculate_entropy(cls_labels)\n",
    "        # Calculate p(t) * H(t)\n",
    "        H_feature += p_t * H_t\n",
    "\n",
    "    # Information Gain = Entropy of Labels - Sum[p(t) * H(t)] where c in C\n",
    "    ig = H_labels - H_feature\n",
    "    return ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_class(Y):\n",
    "    # Create set of classes, counts for each class\n",
    "    classes, counts = np.unique(Y, return_counts=True)\n",
    "    # Return index of highest count\n",
    "    idx = np.argmax(counts)\n",
    "    # Return majority class\n",
    "    return classes[idx].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcce8cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(Y):\n",
    "    return {\n",
    "        \"type\": \"leaf\",\n",
    "        \"result\": majority_class(Y)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcfd8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_train_binary_helper(X: np.ndarray, Y: np.ndarray, remaining_features: list, depth: int):\n",
    "    # print('SUBTREE----------------')\n",
    "    # print(f'X: {X}')\n",
    "    # print(f'Y: {Y}')\n",
    "    # print(f'remaining_features: {remaining_features}')\n",
    "    # print(f'depth: {depth}')\n",
    "    entropy = calculate_entropy(Y) # Calculate the Entropy (H) for the entire training set\n",
    "    # print(f'entropy: {entropy}')\n",
    "    # Base Cases (Return a Leaf)\n",
    "    if entropy == 0:\n",
    "        # print('BASE CASE ENTROPY')\n",
    "        return create_leaf(Y)\n",
    "    \n",
    "    if depth == 0:\n",
    "        # print('BASE CASE DEPTH')\n",
    "        return create_leaf(Y)\n",
    "    \n",
    "    if len(remaining_features) == 0:\n",
    "        # print('BASE CASE NO REMAINING FEATURES')\n",
    "        return create_leaf(Y)\n",
    "\n",
    "    # Calculate Information Gain for each split\n",
    "    igs_for_each_feature = []\n",
    "    for feature_idx in remaining_features:\n",
    "        feature = X[:, feature_idx]\n",
    "        ig_for_this_feature = calculate_information_gain(feature, Y)\n",
    "        igs_for_each_feature.append(ig_for_this_feature)\n",
    "    \n",
    "    # print(f'igs_for_each_feature: {igs_for_each_feature}')\n",
    "    # Choose to split on the feature that gives the best IG\n",
    "    best_feature_idx = np.argmax(igs_for_each_feature)\n",
    "    best_feature = remaining_features[best_feature_idx]\n",
    "    best_ig = igs_for_each_feature[best_feature_idx]\n",
    "\n",
    "    # print(f'best_feature: {best_feature}')\n",
    "    # print(f'best_ig: {best_ig}')\n",
    "\n",
    "    if best_ig == 0:\n",
    "        # print('BASE CASE BEST IG == 0')\n",
    "        return create_leaf(Y)\n",
    "\n",
    "    # Create splits\n",
    "    splits = []\n",
    "    best_feature_col = X[:, best_feature]\n",
    "    # print(f'best_feature_col: {best_feature_col}')\n",
    "    feature_classes = np.unique(best_feature_col)\n",
    "    # print(f'feature_classes: {feature_classes}')\n",
    "    for cls in feature_classes:\n",
    "        selected_rows = (best_feature_col == cls)\n",
    "        X_child: np.ndarray = X[selected_rows]\n",
    "        Y_child = Y[selected_rows]\n",
    "        splits.append((cls, X_child, Y_child))\n",
    "\n",
    "    # print('splits: ', end='')\n",
    "    # pprint(splits)\n",
    "\n",
    "    # Create child nodes\n",
    "    nodes = {}\n",
    "    for cls, X_child, Y_child in splits:\n",
    "        new_depth = depth\n",
    "        if depth != -1:\n",
    "            new_depth -= 1\n",
    "        child_remaining_features = [int(f) for f in remaining_features if f != best_feature]\n",
    "        \n",
    "        if X_child.shape[0] == 0:\n",
    "            nodes[cls.item()] = create_leaf(Y)\n",
    "        else:\n",
    "            nodes[cls.item()] = DT_train_binary_helper(X_child, Y_child, child_remaining_features, new_depth)\n",
    "    \n",
    "    # Create node\n",
    "    node = {\n",
    "        \"type\": \"node\",\n",
    "        \"feature\": int(best_feature),\n",
    "        \"children\": nodes\n",
    "    }\n",
    "\n",
    "    return node\n",
    "\n",
    "def DT_train_binary(X: np.ndarray, Y, max_depth):\n",
    "    # Create array of feature indexes\n",
    "    features = np.arange(X.shape[1])\n",
    "    return DT_train_binary_helper(X, Y, features, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97eb414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test\n",
    "# num = 2\n",
    "# data = load_data(f'../data/data_{num}.txt')\n",
    "# print(data)\n",
    "\n",
    "# X = data[0]\n",
    "# Y = data[1]\n",
    "# tree = DT_train_binary(X, Y, -1)\n",
    "# for i in range (0, 4):\n",
    "#     tree = DT_train_binary(X, Y, i)\n",
    "#     print('TREE------------')\n",
    "#     pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb502d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_make_prediction(x: np.ndarray, DT: dict):\n",
    "    node_type = DT['type']\n",
    "    # Base Cases\n",
    "    if node_type == 'leaf':\n",
    "        result = DT['result']\n",
    "        # print(result)\n",
    "        return result\n",
    "\n",
    "    # Recursive Cases\n",
    "    # pprint(DT)\n",
    "\n",
    "    node_feature = DT['feature']\n",
    "    selected_child = x[node_feature]\n",
    "    return DT_make_prediction(x, DT['children'][selected_child])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36016276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_test_binary(X: np.ndarray, Y: np.ndarray, DT: dict):\n",
    "    # Iterate through the rows of the feature set (X)\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        # Compute a prediction for each row using the decision tree (DT)\n",
    "        row_prediction = DT_make_prediction(x, DT)\n",
    "        # Compile the prediction into a 1D set (predictions) with the same shape as the labels (Y)\n",
    "        predictions.append(row_prediction)\n",
    "\n",
    "    # Find the accuracy by comparing the predictions to the labels\n",
    "    predictions = np.array(predictions)\n",
    "    intersection = predictions == Y\n",
    "    num_matching = np.sum(intersection)\n",
    "    accuracy = num_matching / len(Y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa171059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test\n",
    "\n",
    "# for i in range(0, 4):\n",
    "#     tree = DT_train_binary(X, Y, i)\n",
    "#     print(DT_test_binary(X, Y, tree))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
